{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0862aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\IA\\MachineLearningStudy\\05_FaceRecognition\\venv\\Lib\\site-packages\\face_recognition_models\\__init__.py:7: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The initial plan was to run it on Colab to use the GPU, but we encountered an error related to the dlib library version.\n",
    "Therefore, I opted to proceed locally, as this allows for better control over library versions. \n",
    "While GPU acceleration is faster, it's not strictly necessary for this study, given that we won't be working with a large dataset.\n",
    "\n",
    "To compile dlib, I had to install Microsoft Visual Studio with C++ support.\n",
    "\n",
    "I created a virtual environment and installed the following packages:\n",
    "pip install dlib\n",
    "pip install --upgrade setuptools\n",
    "pip install git+https://github.com/ageitgey/face_recognition_models\n",
    "pip install face_recognition\n",
    "pip install opencv-python\n",
    "\n",
    "To reproduce this on another machine, simply use the requirements.txt file.\"\n",
    "\"\"\"\n",
    "import face_recognition\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "624f45ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the face recognition model with a dataset of known faces.\n",
    "\n",
    "photo_paula = face_recognition.load_image_file(\"training\\\\photo_paula.jpg\")\n",
    "photo_ricardo = face_recognition.load_image_file(\"training\\\\photo_ricardo.jpg\")\n",
    "photo_kate = face_recognition.load_image_file(\"training\\\\photo_kate.jpg\")\n",
    "\n",
    "# Extracts face encodings (feature vectors) from the input image.\n",
    "# Each encoding represents the distinctive features of a face.\n",
    "# As our training dataset has only one face per image, we access the first (and only) encoding using index [0].\n",
    "encoding_paula = face_recognition.face_encodings(photo_paula)[0]\n",
    "encoding_ricardo = face_recognition.face_encodings(photo_ricardo)[0]\n",
    "encoding_kate = face_recognition.face_encodings(photo_kate)[0]\n",
    "\n",
    "known_face_encodings = [\n",
    "    encoding_paula,\n",
    "    encoding_ricardo,\n",
    "    encoding_kate\n",
    "]\n",
    "\n",
    "known_face_labels = [\n",
    "    \"Paula\",\n",
    "    \"Ricardo\",\n",
    "    \"Kate Middleton\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84289f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face recognition process finished!\n"
     ]
    }
   ],
   "source": [
    "# Test the trained face recognition model on a sample image containing multiple people.\n",
    "\n",
    "photo_test_path = \"test\\\\photo_test.jpg\"\n",
    "photo_test = face_recognition.load_image_file(photo_test_path)\n",
    "\n",
    "# Detects each face from the input image.\n",
    "face_test_detections = face_recognition.face_locations(photo_test)\n",
    "# Extracts face encodings.\n",
    "face_test_encodings = face_recognition.face_encodings(photo_test, face_test_detections)\n",
    "\n",
    "# Now, we are going to compare each detected face with our known faces.\n",
    "# We are making the bounding box in the original image.\n",
    "image = cv2.imread(photo_test_path)\n",
    "\n",
    "# Analysing each face in the photo.\n",
    "for (top, right, bottom, left), face_test_encodings in zip(face_test_detections, face_test_encodings):\n",
    "    matches = face_recognition.compare_faces(known_face_encodings, face_test_encodings)\n",
    "\n",
    "    # If a match is found, identify the person.\n",
    "    name = \"Unknown\" \n",
    "    if True in matches:\n",
    "        first_corresponding_index = matches.index(True)\n",
    "        name = known_face_labels[first_corresponding_index]\n",
    "\n",
    "    # Draw a bounding box around the detected face.\n",
    "    # The coordinates are (top, right, bottom, left)\n",
    "    cv2.rectangle(image, (left, top), (right, bottom), (0, 255, 0), 2) # Green rectangle with thickness 2\n",
    "\n",
    "    # Writing the name near to the face.\n",
    "    # The label position is (left, top - 10) in order to stay above the rectangle.\n",
    "    cv2.putText(image, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 255, 0), 2)\n",
    "\n",
    "if not os.path.exists(\"output\"):\n",
    "    os.makedirs(\"output\")\n",
    "\n",
    "success = cv2.imwrite(\"output\\\\photo_test_result.jpg\", image)\n",
    "\n",
    "cv2.imshow(\"Face recognition result\", image)\n",
    "# Wait until a key was pressed to close the window.\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"Face recognition process finished!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
